# HistorIQ
HistorIQ 是一個基於模型上下文協議（Model Context Protocol, MCP）架構的 AI 歷史知識互動平台。整合了 RAG（Retrieval-Augmented Generation）、AI Agent、與本地部署的大語言模型（LLM），讓使用者能夠以自然語言提問歷史事件、人物與文化主題，系統則透過多階段推理與知識檢索生成具脈絡性的回答。

## 主要特色

- **AI 多輪互動**：支援上下文記憶的 AI 回答能力
- **RAG 模型整合**：結合資料庫知識檢索與語言模型生成，提升正確性與可信度
- **MCP 架構實作**：明確劃分 MCP Server / Client / Agent / RAG 模組，架構清晰
- **故事式回應**：支援章節生成與延伸探索，適合用於歷史教育與知識導覽
- **語音輸入與朗讀**：提供講書人模式，打造沉浸式學習體驗
- **本專案遵循 MCP（Model Context Protocol）模型上下文協議 的設計原則，並實作以下關鍵模組與規範：**

| 模組                 | 說明                                                    | 實作狀態   |
| ------------------ | ----------------------------------------------------- | ------ |
| `MCP Server`       | 作為上下文協議核心中介，處理多輪對話狀態、代理分流、語境管理與任務調度                   | ✅ 已完成  |
| `MCP Client (Web)` | 提供使用者互動入口，支援問題輸入、上下文顯示、按鈕互動等                          | ✅ 已完成  |
| `AI Agent`         | 接收 Server 任務委派，進行多步推理與角色化內容生成                         | ✅ 已完成  |
| `RAG Retriever`    | 檢索外部知識內容（如歷史資料庫）並回傳上下文給 AI 模型使用                       | ✅ 已完成  |
| `LLM 接口模組`         | 支援 OpenAI 或本地 LLM（如 LM Studio）語言模型的 API 呼叫與回應解析       | ✅ 已完成  |
| `功能選單控制`           | 故事結束後提供互動按鈕，如「延伸故事」、「轉換風格」等操作，並由 MCP Server 分派對應服務    | ✅ 已完成  |
| `上下文管理機制`          | 每位使用者會有獨立 session ID，並記錄歷史問答脈絡，提供語境維持功能               | ✅ 已完成  |
| `多模組解耦架構`          | 各模組（RAG、Agent、Server、Client）具備明確職責與獨立維護界線             | ✅ 已完成  |
| `延伸任務鏈設計`          | 支援故事後續分支與按鈕觸發任務，如「AI 講書人」、「產出摘要」等                     | ✅ 已完成  |
| `MCP 規範相容性`        | 遵守 MCP 的 Request/Response 與任務分層邏輯，可擴展至更多 Agent 或 Tool | ✅ 初步完成 |

